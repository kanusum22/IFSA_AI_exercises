{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"tester\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.1: Suppose that the performance measure is concerned with just the first T time steps of the environment and ignores everything thereafter. Show that a rational agentâ€™s action may depend not just on the state of the environment but also on the time step it has reached.\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.2: Let us examine the rationality of various vacuum-cleaner agent functions.\n",
    "1. Show that the simple vacuum-cleaner agent function described in Figure 2.3 is indeed rational under the assumptions listed on page \n",
    "2. Describe a rational agent function for the case in which each movement costs one point. Does the corresponding agent program require internal state?\n",
    "3. Discuss possible agent designs for the cases in which clean squares can become dirty and the geography of the environment is unknown. Does it make sense for the agent to learn from its experience in these cases? If so, what should it learn? If not, why not?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.11: Implement a performance-measuring environment simulator for the vacuum-cleaner world depicted in Figure 2.8 and specified on page . Your implementation should be modular so that the sensors, actuators, and environment characteristics (size, shape, dirt placement, etc.) can be changed easily. (Note: for some choices of programming language and operating system there are already implementations in the online code repository.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Environment has location A and location B\n",
    "Input: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to expression here. Maybe you meant '==' instead of '='? (1837259477.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    random-direction = random.choice(items)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "# states = [\"clean\", \"dirty\"]\n",
    "# location = [\"A\", \"B\"]\n",
    "# agent_location = None\n",
    "\n",
    "# Environment Drafting:\n",
    "import random \n",
    "class SimpleEnv:\n",
    "    def __init__(self,agent, N, M):\n",
    "        K = 0\n",
    "        self.positions = [ [ K for i in range(N) ] for j in range(M) ] \n",
    "        self.agent = agent\n",
    "        self.pq = []\n",
    "    def run(self):\n",
    "        newstate = self.agent.action(self.positions[self.agent.get_positionX][self.agent.get_positionX])\n",
    "        self.position[self.agent.get_positionX][self.agent.get_positionX] = newstate\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, posX, posY):\n",
    "        self.positionX = posX\n",
    "        self.positionY = posY\n",
    "        self.performance = 5\n",
    "\n",
    "    # get current coordinates of robot\n",
    "    def get_positionX(self):\n",
    "        return self.positionX\n",
    "    def get_positionY(self):\n",
    "        return self.positionY\n",
    "    \n",
    "    # new position of robot\n",
    "    def set_position(self, posX, posY):\n",
    "        self.positionX = posX\n",
    "        self.positionY = posY\n",
    "\n",
    "    def action(self, state):\n",
    "        if(state == 1):\n",
    "            print(\"need to clean\")\n",
    "            self.performance -= 1\n",
    "            print(\"cleaned\")\n",
    "            self.performance += 10\n",
    "            return 2\n",
    "        elif state == 2:\n",
    "            print(\"already clean - noop\")\n",
    "            return 2\n",
    "\n",
    "def randomAgent():  \n",
    "    N = 10\n",
    "    M = 9    \n",
    "    ag = Agent(1,1)\n",
    "    evn = SimpleEnv(ag, N, M)\n",
    "    for i in range(100):\n",
    "        items = ['N', 'S', 'W', 'E']\n",
    "        random_direction = random.choice(items)\n",
    "        evn.run()\n",
    "        if random_direction == 'N' and ag.get_positionY != 1:\n",
    "            ag.set_position(ag.get_positionX, ag.get_positionY - 1)\n",
    "        elif random_direction == 'S'and ag.get_positionY != N - 2:\n",
    "            ag.set_position(ag.get_positionX, ag.get_positionY + 1)   \n",
    "        elif random_direction == 'W'and ag.get_positionX != 1:\n",
    "            ag.set_position(ag.get_positionX + 1, ag.get_positionY)\n",
    "        elif random_direction == 'E' and ag.get_positionX != M - 2:\n",
    "            ag.set_position(ag.get_positionX - 1, ag.get_positionY)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
